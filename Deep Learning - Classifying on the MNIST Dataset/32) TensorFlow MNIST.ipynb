{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2894a4e",
   "metadata": {},
   "source": [
    "# Deep Neural Network for MNIST Classification\n",
    "\n",
    "We'll apply all the knowledge from the lectures in this section to write a deep neural network. The problem we've chosen is referred to as the \"Hello World\" of deep learning because for most students it is the first deep learning algorithm they see.\n",
    "\n",
    "The dataset is called MNIST and refers to handwritten digit recognition. You can find more about it on Yann LeCun's website (Director of AI Research, Facebook). He is one of the pioneers of what we've been talking about and of more complex approaches that are widely used today, such as covolutional neural networks (CNNs).\n",
    "\n",
    "The dataset provides 70,000 images (28x28 pixels) of handwritten digits (1 digit per image).\n",
    "\n",
    "The goal is to write an algorithm that detects which digit is written. Since there are only 10 digits (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), this is a classification problem with 10 classes.\n",
    "\n",
    "Our goal would be to build a neural network with 2 hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b600419",
   "metadata": {},
   "source": [
    "## Import the relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0420a49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serch\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\serch\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc251783",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cbe7268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfds.load(name) loads a dataset from TensorFlow datasets\n",
    "# tfds.load(name, with_info) loads a dataset from TensorFlow datasets -> with_info = True, provide a tuple containing info about version, features, # samples of the data\n",
    "# tfds.load(name,with_info,as_supervised) loads a datasets from TensorFlow datasets -> as_supervised = True, loads the data in 2-tuple structure [input,output]\n",
    "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
    "\n",
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']\n",
    "\n",
    "# Set number of validation samples\n",
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "\n",
    "# Override number of validation samples\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n",
    "\n",
    "# Set the test_sample in the dedicated variable\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(tf.cast(num_validation_samples, tf.int64), tf.int64)\n",
    "\n",
    "# Scale data\n",
    "def scale(image, label):\n",
    "    \n",
    "    # Make sure values are floats\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    \n",
    "    # Scaling\n",
    "    image /= 255.\n",
    "    return image, label\n",
    "\n",
    "\n",
    "scaled_train_and_validation_data = mnist_train.map(scale)\n",
    "\n",
    "test_data = mnist_test.map(scale)\n",
    "\n",
    "# Shuffling Data\n",
    "\n",
    "# Define buffer size\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "# NOTE\n",
    "# buffer_size = 1 --> Not suffling will happen\n",
    "# bubber_size >= num_samples --> shuffling will happen at once\n",
    "# 1 < buffer_size < num_samples --> it will optimize the computational power\n",
    "\n",
    "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n",
    "\n",
    "validation_data = shuffled_train_and_validation_data.take(num_validation_samples)\n",
    "\n",
    "# Train data\n",
    "train_data = shuffled_train_and_validation_data.skip(num_validation_samples)\n",
    "\n",
    "BATCH_SIZE = 1000\n",
    "\n",
    "# dataset.batch(batch_size) a method that combines the consecutive elemets of a dataset into batches\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "\n",
    "# Validation data\n",
    "validation_data = validation_data.batch(num_validation_samples)\n",
    "\n",
    "test_data = test_data.batch(num_test_samples)\n",
    "\n",
    "# next() load the next element of an iterable object \n",
    "# iter() creates an object which can be iterated one elemet at a time\n",
    "validation_inputs, validation_targets = next(iter(validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e854ab5a",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "\n",
    "#### Outline the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25a91d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\serch\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\serch\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_size = 784\n",
    "output_size = 10\n",
    "\n",
    "# Hidden Layers\n",
    "hidden_layer_size = 1000\n",
    "\n",
    "# tf.keras.Sequetial() function that is laying down the model\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # tf.keras.layers.Flatten(original shape) transform(flattens) a tensor into a vector\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)), # Input layer\n",
    "    \n",
    "    # tf.keras.Dense(output size) takes the input, provided to the model and calculates the dot product of the input and the weight and adds the bias\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 1st hidden layer\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 2nd hidden layer\n",
    "    \n",
    "    tf.keras.layers.Dense(output_size, activation='softmax') # output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922d3575",
   "metadata": {},
   "source": [
    "## Choose the optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6d371d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\serch\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\serch\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mode.compile(optimmizer, loss, metric) configures the model for training\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e948799",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b7f3881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\serch\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\serch\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\serch\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\serch\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 - 4s - loss: 0.4045 - accuracy: 0.8834 - val_loss: 0.1750 - val_accuracy: 0.9488 - 4s/epoch - 69ms/step\n",
      "Epoch 2/5\n",
      "54/54 - 3s - loss: 0.1294 - accuracy: 0.9616 - val_loss: 0.1064 - val_accuracy: 0.9688 - 3s/epoch - 49ms/step\n",
      "Epoch 3/5\n",
      "54/54 - 3s - loss: 0.0815 - accuracy: 0.9758 - val_loss: 0.0825 - val_accuracy: 0.9730 - 3s/epoch - 49ms/step\n",
      "Epoch 4/5\n",
      "54/54 - 3s - loss: 0.0554 - accuracy: 0.9837 - val_loss: 0.0641 - val_accuracy: 0.9803 - 3s/epoch - 49ms/step\n",
      "Epoch 5/5\n",
      "54/54 - 3s - loss: 0.0398 - accuracy: 0.9887 - val_loss: 0.0516 - val_accuracy: 0.9827 - 3s/epoch - 51ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x21badaf6130>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maximum number of epochs\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# fit model\n",
    "# model.fit(data that would be trin, number of epochs, validation data we just created ourselves in the format: (inputs,targets))\n",
    "model.fit(train_data, epochs=NUM_EPOCHS, validation_data=(validation_inputs, validation_targets), verbose =2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b92deb",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2966cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0750 - accuracy: 0.9773\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4deecfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.08. Test accuracy: 97.73%\n"
     ]
    }
   ],
   "source": [
    "print('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
